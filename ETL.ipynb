{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T11:35:15.328480200Z",
     "start_time": "2023-10-15T11:35:11.288025800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: kaggle in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from opendatasets) (1.5.16)\n",
      "Requirement already satisfied: click in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from opendatasets) (8.1.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from opendatasets) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from click->opendatasets) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from kaggle->opendatasets) (2023.7.22)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from kaggle->opendatasets) (2.0.6)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from kaggle->opendatasets) (8.0.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from kaggle->opendatasets) (6.1.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: requests in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from kaggle->opendatasets) (2.31.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from requests->kaggle->opendatasets) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from requests->kaggle->opendatasets) (3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\juniver\\documents\\github\\dataengineeringproject\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "!pip install opendatasets\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T11:39:19.319023100Z",
     "start_time": "2023-10-15T11:35:15.330840900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading arxiv.zip to .\\arxiv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.20G/1.20G [03:36<00:00, 5.95MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This has to be done only once\n",
    "import opendatasets as od\n",
    "# Download the kaggle dataset to local computer\n",
    "# Credentials can be in the same directory in a kaggle.json file and will be read automatically\n",
    "od.download(\"https://www.kaggle.com/datasets/Cornell-University/arxiv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- TODO: The next block should take random lines instead of first ones from the whole dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Get 200K lines for easier data management\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Specify the number of \"lines\" (objects) to write\n",
    "partition_size = 50000\n",
    "number_of_partitions = 4\n",
    "all_data = number_of_partitions * partition_size\n",
    "data = []\n",
    "\n",
    "file_path = \"./arxiv/arxiv-metadata-oai-snapshot.json\"\n",
    "\n",
    "# Open the existing JSON file for reading\n",
    "with open(file_path, 'r') as read_file:\n",
    "    for i, line in enumerate(read_file):\n",
    "        if i >= all_data:\n",
    "            break\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Create a directory for partitions\n",
    "partitions_path = './arxiv/partitions'\n",
    "\n",
    "# Check whether directory already exists\n",
    "if not os.path.exists(partitions_path):\n",
    "    os.mkdir(partitions_path)\n",
    "\n",
    "\n",
    "for i in range(number_of_partitions):\n",
    "    # Select the first num_lines objects\n",
    "    selected_data = data[i * partition_size:(i + 1) * partition_size]\n",
    "\n",
    "    # Open a new JSON file for writing\n",
    "    with open(partitions_path + '/partition' + str(i) + '.json', 'w') as write_file:\n",
    "        for json_obj in selected_data:\n",
    "            # Use json.dumps to convert the JSON object to a string\n",
    "            json_str = json.dumps(json_obj)\n",
    "            # Write the string to the file\n",
    "            write_file.write(json_str + '\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T11:39:33.329517800Z",
     "start_time": "2023-10-15T11:39:19.325607300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id            submitter  \\\n",
      "0  802.2703           Lifeng Lai   \n",
      "1  802.2704          Pawan Kumar   \n",
      "2  802.2705          Jan Reimann   \n",
      "3  802.2706  Christian Hoelbling   \n",
      "4  802.2707       Danny Calegari   \n",
      "\n",
      "                                             authors  \\\n",
      "0  Lifeng Lai, Hesham El Gamal, Hai Jiang and H. ...   \n",
      "1            Pawan Kumar and Erin McMahon, UT Austin   \n",
      "2                    Jan Reimann, Theodore A. Slaman   \n",
      "3  S. Durr, Z. Fodor, C. Hoelbling, R. Hoffmann, ...   \n",
      "4                                     Danny Calegari   \n",
      "\n",
      "                                               title  \\\n",
      "0  Optimal Medium Access Protocols for Cognitive ...   \n",
      "1  A general scheme for modeling gamma-ray burst ...   \n",
      "2                    Measures and their random reals   \n",
      "3  Scaling study of dynamical smeared-link clover...   \n",
      "4  Nonsmoothable, locally indicable group actions...   \n",
      "\n",
      "                                            comments  \\\n",
      "0  To appear in the Proceedings of the 6th Intern...   \n",
      "1              Published in MNRAS Jan 2008, 56 pages   \n",
      "2                                               None   \n",
      "3  11 pages, 7 figures, aps style. Final publishe...   \n",
      "4                                  4 pages, 1 figure   \n",
      "\n",
      "                             journal-ref                               doi  \\\n",
      "0                                   None                              None   \n",
      "1     Mon.Not.Roy.Astron.Soc.384:33,2008  10.1111/j.1365-2966.2007.12621.x   \n",
      "2                                   None                              None   \n",
      "3               Phys.Rev.D79:014501,2009        10.1103/PhysRevD.79.014501   \n",
      "4  Algebr. Geom. Topol. 8 (2008) 609-613            10.2140/agt.2008.8.609   \n",
      "\n",
      "  report-no               categories  \\\n",
      "0      None      cs.IT cs.NI math.IT   \n",
      "1      None                 astro-ph   \n",
      "2      None          math.LO math.PR   \n",
      "3      None                  hep-lat   \n",
      "4      None  math.DS math.GR math.GT   \n",
      "\n",
      "                                             license  \\\n",
      "0  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "2  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "3  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "4  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0    This paper focuses on the design of medium a...   \n",
      "1    We describe a general method for modeling ga...   \n",
      "2    We study the randomness properties of reals ...   \n",
      "3    We present a framework for phenomenological ...   \n",
      "4    By the Thurston stability theorem, a group o...   \n",
      "\n",
      "                                            versions update_date  \\\n",
      "0  [{'version': 'v1', 'created': 'Tue, 19 Feb 200...  2008-02-20   \n",
      "1  [{'version': 'v1', 'created': 'Tue, 19 Feb 200...  2009-11-13   \n",
      "2  [{'version': 'v1', 'created': 'Tue, 19 Feb 200...  2013-05-16   \n",
      "3  [{'version': 'v1', 'created': 'Tue, 19 Feb 200...  2009-02-10   \n",
      "4  [{'version': 'v1', 'created': 'Tue, 19 Feb 200...  2014-10-01   \n",
      "\n",
      "                                      authors_parsed  \n",
      "0  [[Lai, Lifeng, ], [Gamal, Hesham El, ], [Jiang...  \n",
      "1  [[Kumar, Pawan, ], [McMahon, Erin, ], [Austin,...  \n",
      "2        [[Reimann, Jan, ], [Slaman, Theodore A., ]]  \n",
      "3  [[Durr, S., ], [Fodor, Z., ], [Hoelbling, C., ...  \n",
      "4                              [[Calegari, Danny, ]]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "partition_path = partitions_path + \"/partition1.json\"\n",
    "\n",
    "# Read the data into pandas dataframe\n",
    "df = pd.read_json(partition_path, lines=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T11:39:35.863076800Z",
     "start_time": "2023-10-15T11:39:33.329517800Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
